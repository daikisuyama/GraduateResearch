\chapter{実験}

本章では、実験で使用したデータセットの説明を行った後に実験の結果及び考察をまとめる。

\section{データセット}

本研究のデータセットの作成方法及びその形式についての説明を行う。

\subsection{データセットの作成方法}

楽譜作成ソフトのMuseScore\footnote{\url{https://musescore.org/}}により国際の階名表記でA0からC8までの半音をwav形式で88音生成した。これらは88鍵のピアノで出すことのできる音であり、最も一般的な音域として今回の実験では選んだ。

\subsection{データ形式}

音のファイル形式としては非圧縮形式のWAVを用いる。MP3やMP4などの非可逆圧縮形式も一般には広く用いられるが、音波の波形データを直接保持しているために扱いやすいWAVを本論文で用いることにした。また、WAVは波形データ以外にメタデータを持ち、本論文で扱うメタデータについて以下で説明をする。

\begin{description}

\item[サンプリング周波数]\mbox{}

サンプリング周波数とは、デジタル信号の1秒あたりの標本化の回数のことである。本論文では44100Hzに固定して実験を行う。

\item[サンプリング数]\mbox{}

サンプリング数とは、デジタル信号の標本化の合計の回数のことである。本論文では44100回に固定して実験を行う。

\item[量子化ビット数]\mbox{}

量子化ビット数とは、デジタル信号の細かさを表現するビット数のことである。本論文では16bitに固定して実験を行う。

\item[チャンネル数]\mbox{}

チャンネル数とは、モノラルな音声の出力の総数のことである。本論文では1に固定して実験を行う。

\end{description}

\section{実験環境}

Pix2pixを用いてギターからハープへの音の変換を行うことを目標に実験を行った。ギターとハープの組は十分に音色が異なる楽器として選んだ。また、学習とテストの際のパラメータは\ref{sec:appendix}の\ref{sec:appendix_params}に示す。

\section{生成モデルの表現力}

生成モデルの表現力を測るために学習データとテストデータに同じ88音を用いて実験を行った。また、過学習を防ぐために毎エポックのそれぞれのデータの振幅を$c \in [0.3,1]$倍して学習を行った。

\subsection{lossのグラフ}


\subsection{考察}

本実験では波形の観察を通して考察を行う。

%結果、考察

\section{生成モデルの汎化能力}

生成モデルの表現力が十分にあることを確認したので、その汎化能力を調べる実験を行った。また、先程の実験と同様に毎エポックのそれぞれのデータの振幅を$c \in [0.3,1]$倍して学習を行った。

さらに、汎化能力を調べるために、88音のデータに対し4分割交差検証を行った。この際にデータはランダムに分割しており、その区分は\ref{sec:appendix}の\ref{sec:appendix_split}に示した。

\subsection{lossのグラフ}

\subsection{考察}

本実験では波形の観察を通して考察を行う。

%結果、考察

%仮説：周波数を勝手に理解できるのは？