\chapter{背景：ニューラルネットワーク}

本章では、Multilayer~perceptron及びその応用例のGenerative~Adversarial~Networksの説明を行った後、Generative~Adversarial~Networksを画像の変換に応用したPix2pixを紹介する。

\section{教師あり学習}

教師あり学習は機械学習の手法の一つである。機械学習とは、学習データと呼ばれるデータに含まれる特徴をコンピュータプログラム~(モデル)~が自動で学習し、学習したモデルを用いて何らかの問題を解く手法のことである。また、教師あり学習では、説明変数と対応するべき目的変数のペアとして学習データが与えられる。

\subsection{教師あり学習の目的}

$X,Y$をそれぞれ説明変数と目的変数の空間とすると、$f:X\rightarrow Y$のうち任意の$\boldsymbol{x} \in X$について正しい値を出力する関数$f^{'}$を表現するモデルを作成することが教師あり学習の目的である。また、$\boldsymbol{x} \in X$について、$f(\boldsymbol{x})$の$f^{'}(\boldsymbol{x})$への近似の程度を評価する関数を損失関数$L$と呼ぶ。よって、損失関数は$\mathbb{R}^+$を非負の実数として$L:Y \times Y \rightarrow \mathbb{R}^+$と定義でき、値が小さいほど近似の程度が良い。

\subsection{教師あり学習モデルの学習と汎化}

任意の$\boldsymbol{x} \in X$と対応する$\boldsymbol{y} \in Y$の組を用意することは現実的には難しいため、学習データはランダムに抽出されているという仮定のもとにある。この時、学習データに含まれる任意の説明変数$\boldsymbol{x}$について損失関数$L$の値の期待値を小さくするように学習を行う。すなわち、目的関数は式\ref{eq:SL1}となる。

\begin{align}
    \label{eq:SL1}
    \hat{f}=\argmin _{f} \mathbb{E}[L(\boldsymbol{y},f(\boldsymbol{x}))]
\end{align}

また、$\hat{f}$はモデルの学習結果であるが、学習データに含まれる説明変数のみで最適であるため、$\hat{f}$は$f^{'}$に一致するとは限らない。したがって、学習データとは別に評価データを用意し、モデルの評価データに対する性能~(汎化性能)~を測定する必要がある。

%機械学習は、教師あり学習、教師なし学習、強化学習、の三つに主に分類することができる。
%教師あり学習とは、学習データにおいて入力値に対応する出力値がわかる機械学習の手法である。また、出力値が離散値である問題を分類問題と呼び、出力値が連続値である問題を回帰問題と呼ぶ。
%教師なし学習とは、学習データにおいて入力値に対応する出力値がわからない機械学習の手法である。例としては、データ内で類似したもの同士をまとめるクラスタリングがあげられる。
%強化学習とは、報酬を最大化させるために特定の状況での適切なアクションを選択する機械学習の手法である。


\section{多層パーセプトロン}

多層パーセプトロン~(Multilayer~perceptron、MLP)~は教師あり学習の手法のニューラルネットワークの一つである。本論文では、MLPのことをニューラルネットワークと呼ぶ。

\subsection{MLPの定式化}

MLPは$\hat{f}$を複数のアフィン変換と非線形関数を合成した関数により表現されるため、式\ref{eq:MLP1}で定式化される。

\begin{align}
    \label{eq:MLP1}
    F_{MLP}(\boldsymbol{x})&=f_{n}(W_{n}(f_{n-1}(W_{n-1}\cdots(f_{1}(W_{1}\boldsymbol{x}+\boldsymbol{b_{1}}))\cdots+\boldsymbol{b_{n-1}}))+\boldsymbol{b_{n}})
\end{align}

ここで、$\boldsymbol{x}$は実ベクトル,$n$は1以上の整数,$f_{i}$は$i$番目の非線形関数,$W_{i}$は$i$番目の行列,$\boldsymbol{b_{i}}$は$i$番目の実ベクトルである。また、MLPにおいては、$n$を層数、$W_i,\boldsymbol{b_i}$を$i$番目の層の重み、と呼ぶ。

\subsection{MLPの学習}

多層パーセプトロンの学習では、任意の$i$で層の重み$W_i,\boldsymbol{b_i}$の値を適切に定める必要がある。また、損失関数を減少させる方向に学習は進むため、式\ref{eq:MLP2}にしたがって層の重み$W_i,\boldsymbol{b_i}$は更新される~(勾配降下法)~。

\begin{align}
    \label{eq:MLP2}
    W _i &\leftarrow W_i - \eta \frac{d L}{dW_i} \\
    \boldsymbol{b _i} &\leftarrow \boldsymbol{b_i} - \eta \frac{d L}{dW_i}
\end{align}

%Adam,SGDの原著論文に目を通す
ここで、$\eta$は任意の正の実数であり、学習率と呼ばれる。なお、この学習率を適切に設定するためにStochastic~Gradient~Descent~\cite{SGD}やAdam~\cite{Adam}などのアルゴリズムが用いられる。

\subsection{MLPの損失関数の例}

多層パーセプトロンにおける損失関数には、式\ref{eq:MLP3}の平均二乗誤差や式\ref{eq:MLP4}の平均絶対誤差などが用いられる。

\begin{align}
    \label{eq:MLP3}
    L_{MSE}&=\frac{1}{n}\sum _{j} {(\boldsymbol{y_j} - F_{MLP}(\boldsymbol{x_j})^2}\\
    \label{eq:MLP4}
    L_{MAE}&=\frac{1}{n}\sum _{j} {|\boldsymbol{y_j} - F_{MLP}(\boldsymbol{x_j})|}
\end{align}

\section{畳み込みニューラルネットワーク}

%これ必要だ

\section{敵対的生成ネットワーク}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\hsize]{figure/GAN_net.png}
\caption{GANのネットワーク、図は文献~\cite{pix2pix}のFigure~1を用いて作成。}
\label{fig:GAN_net}
\end{center}
\end{figure}

敵対的生成ネットワーク~(Generative~Adversarial~Networks、GAN)~\cite{GAN}は、ニューラルネットワークの応用例であり、学習データの特徴を持つ擬似的なデータを生成することを目指す手法である。この手法は実在しないアイドルの写真を生成する際などに用いられる~\cite{idol}。

\subsection{GANの学習}

GANは図\ref{fig:GAN_net}のように二つのニューラルネットワークで構成される。それぞれのネットワークはDiscriminator~(識別モデル)~とGenerator~(生成モデル)~と呼ばれる。二つのネットワークはランダムに初期化された後に競合的に学習を進める。まず、識別モデルはデータがFake~data~(生成モデルの出力)~とReal~data~(学習データ)~のどちらであるかを識別できるように学習を進める。そして、生成モデルは識別モデルが学習データであると誤って識別するように、Noise~(ノイズ)~を元に学習データに近いデータを出力する。この二つの学習を交互に繰り返すことで、漸進的に生成モデルが学習データにより近いデータを生成できるようになると期待される。また、ノイズは適当な次元の実ベクトルであり、生成モデルの出力の揺らぎを表現する潜在変数の役割を果たす。

\subsection{GANの定式化}

GANでは、生成モデルの目的関数は式\ref{eq:GAN_G}、識別モデルの目的関数は式\ref{eq:GAN_D}として定式化される。

\begin{align}
    \label{eq:GAN_G}
    \argmin _{\theta_G}& \mathbb{E}_{\boldsymbol{z}}[\log (1-D(G(\boldsymbol{z};\theta_G);\theta_D))]\\
    \label{eq:GAN_D}
    \argmax _{\theta_D}& \mathbb{E}_{\boldsymbol{x}}[\log D(\boldsymbol{x};\theta_D)]+\mathbb{E}_{\boldsymbol{z}}[\log (1-D(G(\boldsymbol{z};\theta_G);\theta_D))]
\end{align}


ここで、$\boldsymbol{x}$は学習データ、$\boldsymbol{z}$は生成モデルへの入力のノイズ、$G(\boldsymbol{z};\theta_G)$はノイズ$\boldsymbol{z}$を入力とする生成モデル、$D(\cdot;\theta_D)$は識別モデル、$\theta_G$は生成モデル$G$のパラメータ、$\theta_D$は識別モデル$D$のパラメータ、である。

\section{Pix2pix}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\hsize]{figure/pix2pix_net.png}
\caption{pix2pixのネットワーク、図は文献~\cite{pix2pix}のFigure~1を用いて作成。}
\label{fig:pix2pix_net}
\end{center}
\end{figure}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\hsize]{figure/pix2pix_img.png}
\caption{pix2pixのスタイル変換の例、図は文献~\cite{pix2pix}のFigure~1を用いて作成。}
\label{fig:pix2pix_img}
\end{center}
\end{figure}

Pix2pix~\cite{pix2pix}は、図\ref{fig:pix2pix_net}のようにネットワークの入力に変換元の画像を~Condition~(条件)~として与えることで画像の変換を行うGANである。特定の条件をネットワークの入力に与えるGANとしてはConditional~GAN~(CGAN)~\cite{CGAN}が初めて考案されたが、Pix2pixは与えられた条件画像の構造を維持したまま変換するという点でCGANとは異なる。具体的には、図\ref{fig:pix2pix_img}のように線画から写真への変換や白黒画像からカラー画像への変換を行うことができる。

そして、Pix2pixにおいては、生成モデルの目的関数は式\ref{eq:pix2pix_G}、識別モデルの目的関数は式\ref{eq:pix2pix_D}として定式化される。

\begin{align}
    \label{eq:pix2pix_G}
    \argmin _{\theta_G}& \mathbb{E}_{\boldsymbol{y}, \boldsymbol{z}}[\log (1-D(\boldsymbol{y}, G(\boldsymbol{y}, \boldsymbol{z}; \theta_G); \theta_D))]+\mathbb{E}_{\boldsymbol{x}, \boldsymbol{y}, \boldsymbol{z}}[\|\boldsymbol{x}-G(\boldsymbol{y}, \boldsymbol{z}; \theta_G)\|_{1}]\\
    \label{eq:pix2pix_D}
    \argmax _{\theta_D}& \mathbb{E}_{\boldsymbol{x}, \boldsymbol{y}}[\log D(\boldsymbol{x}, \boldsymbol{y}; \theta_D)]+\mathbb{E}_{\boldsymbol{y}, \boldsymbol{z}}[\log (1-D(\boldsymbol{y}, G(\boldsymbol{y}, \boldsymbol{z}; \theta_G); \theta_D))]
\end{align}

ここで、$\boldsymbol{x}$は変換先の学習データ、$\boldsymbol{y}$は変換元の学習データ、$\boldsymbol{z}$は生成モデルへの入力のノイズ、$G(\boldsymbol{y},\boldsymbol{z};\theta_G)$は$\boldsymbol{y}$を条件としノイズ$\boldsymbol{z}$を入力とする生成モデル、$D(\boldsymbol{y},\cdot;\theta_D)$は$\boldsymbol{y}$を条件とする識別モデル、$\theta_G$は生成モデル$G$のパラメータ、$\theta_D$は識別モデル$D$のパラメータ、である。

\subsection{生成モデルの構造}

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.95\hsize]{figure/u-net.png}
\caption{生成モデルのネットワーク、図は文献~\cite{pix2pix}のFigure~1とFigure~3を用いて作成。}
\label{fig:u-net}
\end{center}
\end{figure}

Pix2pixの生成モデルには、図\ref{fig:u-net}のようにEncoder-Decoder型のネットワークが用いられる。ただし、変換元の画像と返還後の画像で共通する基本構造であるピクセルの対応関係を維持するために、Skip~Connection~(スキップコネクション)~が用いられる~\cite{u-net}。

%スキップコネクションの説明

また、ノイズとしては実ベクトルではなくDropoutが用いられる~\cite{Dropout}。Dropoutとは、ニューラルネットワークの重みの更新の際にランダムにいくつかの重みを0として無視する手法のことである。

\subsection{識別モデルの構造}

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.95\hsize]{figure/patchgan.png}
\caption{通常のGANとPatchGANの比較、図は文献~\cite{pix2pix}のFigure~1を用いて作成。}
\label{fig:patchgan}
\end{center}
\end{figure}

Pix2pixの識別モデルには、PatchGANという手法が用いられる。PatchGANは図\ref{fig:patchgan}のように画像全体ではなくパッチと呼ばれる小領域ごとに真偽を求めて平均を出力とする。これにより、局所的な識別精度が高まることが期待される。